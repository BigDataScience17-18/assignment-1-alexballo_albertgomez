{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering by rows\n",
    "## Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasetControl/co2c0000339.txt\n",
      "./datasetControl/co2c0000338.txt\n",
      "./datasetControl/co2c0000337.txt\n",
      "./datasetControl/co2c0000342.txt\n",
      "./datasetControl/co2c0000341.txt\n",
      "./datasetControl/co2c0000340.txt\n",
      "./datasetControl/co2c0000344.txt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0f5b35d511b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;31m# cont is the counter which goes through all the files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 df.loc[cont]=[user[counterinside],alcoholic[counterinside],paradigm[counterinside],replication[counterinside],channel[counterinside],min[0],max[0],\n\u001b[0;32m---> 86\u001b[0;31m                               sd[0],mean[0],median[0],iqr,quantil0[0],quantil1[0],median[0],quantil3[0],quantil4[0]]\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0mcont\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcont\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_has_valid_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m    443\u001b[0m                                        name=indexer)\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_update_cacher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(self, other, ignore_index, verify_integrity)\u001b[0m\n\u001b[1;32m   5192\u001b[0m             \u001b[0mto_concat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5193\u001b[0m         return concat(to_concat, ignore_index=ignore_index,\n\u001b[0;32m-> 5194\u001b[0;31m                       verify_integrity=verify_integrity)\n\u001b[0m\u001b[1;32m   5195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5196\u001b[0m     def join(self, other, on=None, how='left', lsuffix='', rsuffix='',\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, copy)\u001b[0m\n\u001b[1;32m    211\u001b[0m                        \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m                        copy=copy)\n\u001b[0;32m--> 213\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    406\u001b[0m             new_data = concatenate_block_managers(\n\u001b[1;32m    407\u001b[0m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                 copy=self.copy)\n\u001b[0m\u001b[1;32m    409\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m                 \u001b[0mnew_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mconcatenate_block_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m   5201\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5202\u001b[0m             b = make_block(\n\u001b[0;32m-> 5203\u001b[0;31m                 \u001b[0mconcatenate_join_units\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5204\u001b[0m                 placement=placement)\n\u001b[1;32m   5205\u001b[0m         \u001b[0mblocks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mconcatenate_join_units\u001b[0;34m(join_units, concat_axis, copy)\u001b[0m\n\u001b[1;32m   5330\u001b[0m     to_concat = [ju.get_reindexed_values(empty_dtype=empty_dtype,\n\u001b[1;32m   5331\u001b[0m                                          upcasted_na=upcasted_na)\n\u001b[0;32m-> 5332\u001b[0;31m                  for ju in join_units]\n\u001b[0m\u001b[1;32m   5333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5334\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   5330\u001b[0m     to_concat = [ju.get_reindexed_values(empty_dtype=empty_dtype,\n\u001b[1;32m   5331\u001b[0m                                          upcasted_na=upcasted_na)\n\u001b[0;32m-> 5332\u001b[0;31m                  for ju in join_units]\n\u001b[0m\u001b[1;32m   5333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5334\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget_reindexed_values\u001b[0;34m(self, empty_dtype, upcasted_na)\u001b[0m\n\u001b[1;32m   5630\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5631\u001b[0m                 values = algos.take_nd(values, indexer, axis=ax,\n\u001b[0;32m-> 5632\u001b[0;31m                                        fill_value=fill_value)\n\u001b[0m\u001b[1;32m   5633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5634\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, out, fill_value, mask_info, allow_fill)\u001b[0m\n\u001b[1;32m   1377\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'F'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1379\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m     func = _get_take_nd_function(arr.ndim, arr.dtype, out.dtype, axis=axis,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from os import listdir\n",
    "root=\"./datasetControl\";\n",
    "\n",
    "\n",
    "# It is going to take a while to read all the data\n",
    "linecounter= 0\n",
    "filecounter=0\n",
    "df = pd.DataFrame(columns=['user_id', 'alcoholic', 'paradigm','replication','Channel','Min','Max','Sd','Mean',\n",
    "                               'Median','IQR','0.025','0.25','0.5','0.75','0.975'])\n",
    "cont=0;\n",
    "for file in listdir(\"./datasetControl\"):\n",
    "\n",
    "\n",
    "        # Renaming the file\n",
    "        \n",
    "        filecounter= filecounter + 1\n",
    "        \n",
    "        file_root = root + \"/\" + file\n",
    "        print(file_root)\n",
    "        if(file!=\".DS_Store\"):\n",
    "            read_file = open(file_root, 'r')\n",
    "            read_file.readline()\n",
    "            counterinside=0\n",
    "            user = []\n",
    "            alcoholic=[]\n",
    "            paradigm=[]\n",
    "            replication=[]\n",
    "            channel=[]\n",
    "           \n",
    "            # For each line we separate the values to add them in the created dataframe\n",
    "            for line in read_file:\n",
    "                if(filecounter<=5):\n",
    "                    linecounter= linecounter + 1\n",
    "                \n",
    "                firstline = line.split(\"  \")\n",
    "                lineeg=[]\n",
    "\n",
    "                for i in range(len(firstline)-1):\n",
    "                    \n",
    "\n",
    "                    if i==0:\n",
    "                        user.append(float(firstline[i]))\n",
    "                    elif i==1:\n",
    "                        alcoholic.append(firstline[i])\n",
    "\n",
    "                    elif i==2:\n",
    "\n",
    "                        paradigm.append(firstline[i])\n",
    "\n",
    "                    if i==3:\n",
    "\n",
    "                        replication.append(float(firstline[i]))\n",
    "                    elif i>=4:\n",
    "                        if i==4:\n",
    "                            channelline=firstline[i].split(\" \")\n",
    "                            channel.append(channelline[0])\n",
    "                            if channelline[1][0]=='c':\n",
    "                                canal=channelline[1][1:]\n",
    "                                lineeg.append(float(canal))\n",
    "\n",
    "                            else:\n",
    "                                lineeg.append(float(channelline[1]))\n",
    "\n",
    "                        else:\n",
    "                            lineeg.append(float(firstline[i]))\n",
    "\n",
    "              \n",
    "                datachannel = pd.DataFrame(lineeg)\n",
    "                min = datachannel.min()\n",
    "                max = datachannel.max()\n",
    "                sd = datachannel.std()\n",
    "                mean = datachannel.mean()\n",
    "                quantil0=datachannel.quantile(.025)\n",
    "                quantil1=datachannel.quantile(.25)\n",
    "                median=datachannel.quantile(.5)\n",
    "                quantil3=datachannel.quantile(.75)\n",
    "                quantil4=datachannel.quantile(.975)\n",
    "                iqr=quantil3[0]-quantil1[0]\n",
    "                # counterinside is the one which goes through the lines of the current file\n",
    "                # cont is the counter which goes through all the files\n",
    "                df.loc[cont]=[user[counterinside],alcoholic[counterinside],paradigm[counterinside],replication[counterinside],channel[counterinside],min[0],max[0],\n",
    "                              sd[0],mean[0],median[0],iqr,quantil0[0],quantil1[0],median[0],quantil3[0],quantil4[0]]\n",
    "               \n",
    "                cont= cont +1\n",
    "                counterinside= counterinside + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate target and features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "features =['Min','Max','Sd','Mean',\n",
    "                           'Median','IQR','0.025','0.25','0.5','0.75','0.975']\n",
    "# Separar les variables explicatives\n",
    "x = df.loc[:, features].values\n",
    "# Separating out the target\n",
    "y = df.loc[:,['alcoholic']].values\n",
    "print(y)\n",
    "\n",
    "\n",
    "# Standardizing the features\n",
    "x = StandardScaler().fit_transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Keeping 2 components\n",
    "pca = PCA(n_components=2)\n",
    "# Explicative variables transformation\n",
    "principalComponents = pca.fit_transform(x)\n",
    "principalDf = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['component 1', 'component 2'])\n",
    "principalDf.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important explicative variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relationship important data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.DataFrame(x, columns=features)\n",
    "\n",
    "# data normalitzada\n",
    "from sklearn import preprocessing\n",
    "data_scaled = pd.DataFrame(preprocessing.scale(df_1),columns = df_1.columns) \n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit_transform(data_scaled)\n",
    "\n",
    "# components relacionats amb les variables explicatives\n",
    "pd.DataFrame(pca.components_,columns=data_scaled.columns,index = ['PC-1','PC-2','PC-3'])\n",
    "# The columns we are gonna keep are pc-1: 0.25, pc-2:Sd and pc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Control graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalDf = pd.concat([principalDf, df[['alcoholic']]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualization of the alcoholic users\n",
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('Component 1', fontsize = 15)\n",
    "ax.set_ylabel('Component 2', fontsize = 15)\n",
    "ax.set_title('2 component PCA', fontsize = 20)\n",
    "targets = ['a', 'c']\n",
    "colors = ['r', 'b']\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = finalDf['alcoholic'] == target\n",
    "    ax.scatter(finalDf.loc[indicesToKeep, 'component 1']\n",
    "                ,finalDf.loc[indicesToKeep, 'component 2']\n",
    "               , c = color\n",
    "               , s = 50)\n",
    "ax.legend(targets)\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It only has to be used once because of the unnecessary columns have been removed and we only take the three explicative variables \n",
    "# which are more relevant\n",
    "df= df.drop(df.columns[[5,6,7,8,9,10,11,12,13,14,15]], axis=1)\n",
    "resultDf = pd.concat([df, principalDf], axis=1)\n",
    "print(resultDf)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
